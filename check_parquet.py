#!/usr/bin/env python3

import pandas as pd
import numpy as np
import sys
import os

# confidence.py ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))
from data.confidence import ConfidenceCalculator

# Parquet íŒŒì¼ ë¡œë“œ
df = pd.read_parquet('/workspace/output_s/generated/sample_400/raw_generated.parquet')

print('ğŸ“Š output_token_count í†µê³„ ë¶„ì„')
print('=' * 50)

# ê¸°ë³¸ í†µê³„ ì •ë³´
print('\nğŸ”¢ ê¸°ë³¸ í†µê³„:')
print(f'  - ì „ì²´ ì‘ë‹µ ìˆ˜: {len(df):,}')
print(f'  - í‰ê·  í† í° ìˆ˜: {df["output_token_count"].mean():.2f}')
print(f'  - ì¤‘ì•™ê°’ í† í° ìˆ˜: {df["output_token_count"].median():.2f}')
print(f'  - ìµœì†Œ í† í° ìˆ˜: {df["output_token_count"].min()}')
print(f'  - ìµœëŒ€ í† í° ìˆ˜: {df["output_token_count"].max()}')
print(f'  - í‘œì¤€í¸ì°¨: {df["output_token_count"].std():.2f}')

# ë¶„ìœ„ìˆ˜ ë¶„ì„
print('\nğŸ“ˆ ë¶„ìœ„ìˆ˜ ë¶„ì„:')
percentiles = [10, 25, 50, 75, 90, 95, 99]
for p in percentiles:
    value = np.percentile(df["output_token_count"], p)
    print(f'  - {p}% ë¶„ìœ„ìˆ˜: {value:.0f}')

# 10%ì”© ìë¥´ë˜ stride 5%ë¡œ ê²¹ì¹˜ëŠ” êµ¬ê°„ ë¶„ì„
print('\nğŸ“Š í† í° ìˆ˜ êµ¬ê°„ë³„ ë¶„ì„ (10% êµ¬ê°„, stride 5%):')
token_counts = df["output_token_count"]

# ë¶„ìœ„ìˆ˜ ê³„ì‚° (5% ê°„ê²©ìœ¼ë¡œ)
percentiles = list(range(0, 101, 5))  # 0%, 5%, 10%, ..., 100%
percentile_values = [np.percentile(token_counts, p) for p in percentiles]

print(f'  ë¶„ìœ„ìˆ˜ ê°’ë“¤: {[int(v) for v in percentile_values]}')

# ConfidenceCalculator ì´ˆê¸°í™”
confidence_calc = ConfidenceCalculator(group_size=10)

# ê° êµ¬ê°„ë³„ ë¶„ì„ (10% êµ¬ê°„, 5% stride)
print('\n  êµ¬ê°„ë³„ ìƒì„¸ ë¶„ì„:')
for i in range(0, len(percentiles)-2, 1):  # stride 5% (ì¸ë±ìŠ¤ 1ì”© ì¦ê°€)
    start_pct = percentiles[i]
    end_pct = percentiles[i+2]  # 10% êµ¬ê°„
    
    start_val = int(percentile_values[i])
    end_val = int(percentile_values[i+2])
    
    # í•´ë‹¹ êµ¬ê°„ì˜ ë°ì´í„° í•„í„°ë§
    mask = (token_counts >= start_val) & (token_counts <= end_val)
    range_df = df[mask]
    
    if len(range_df) == 0:
        continue
        
    print(f'\n  êµ¬ê°„ {start_pct}%-{end_pct}% ({start_val}-{end_val} í† í°):')
    print(f'    - ì‘ë‹µ ìˆ˜: {len(range_df):,}ê°œ ({len(range_df)/len(df)*100:.2f}%)')
    
    # Confidence score ê³„ì‚° (logprobs ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
    if 'logprobs' in df.columns:
        # í•´ë‹¹ êµ¬ê°„ì˜ logprobs ì¶”ì¶œ
        range_logprobs = range_df['logprobs'].tolist()
        
        # ê° ì‘ë‹µì˜ confidence score ê³„ì‚°
        confidence_scores = []
        for logprobs in range_logprobs:
            # logprobsê°€ Noneì´ ì•„ë‹ˆê³  ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
            if logprobs is not None and hasattr(logprobs, '__len__') and len(logprobs) > 0:
                try:
                    scores = confidence_calc.calculate_all_confidence_scores(logprobs)
                    confidence_scores.append(scores)
                except Exception as e:
                    print(f"      ì‹ ë¢°ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
                    continue
        
        if confidence_scores:
            # í‰ê·  confidence score ê³„ì‚°
            mean_group_conf = np.mean([s['mean_group_confidence'] for s in confidence_scores])
            bottom_10_conf = np.mean([s['bottom_10_percent_confidence'] for s in confidence_scores])
            tail_conf = np.mean([s['tail_confidence'] for s in confidence_scores])
            
            print(f'    - í‰ê·  ê·¸ë£¹ ì‹ ë¢°ë„: {mean_group_conf:.4f}')
            print(f'    - í•˜ìœ„ 10% ì‹ ë¢°ë„: {bottom_10_conf:.4f}')
            print(f'    - ê¼¬ë¦¬ ì‹ ë¢°ë„: {tail_conf:.4f}')
        else:
            print(f'    - ì‹ ë¢°ë„ ê³„ì‚° ë¶ˆê°€ (logprobs ë°ì´í„° ì—†ìŒ)')
    else:
        print(f'    - ì‹ ë¢°ë„ ê³„ì‚° ë¶ˆê°€ (logprobs ì»¬ëŸ¼ ì—†ìŒ)')
    
    # í† í° ìˆ˜ í†µê³„
    print(f'    - í‰ê·  í† í° ìˆ˜: {range_df["output_token_count"].mean():.1f}')
    print(f'    - ì¤‘ì•™ê°’ í† í° ìˆ˜: {range_df["output_token_count"].median():.1f}')
    print(f'    - ìµœì†Œ/ìµœëŒ€ í† í° ìˆ˜: {range_df["output_token_count"].min()}/{range_df["output_token_count"].max()}')

# 4096 í† í° ì‘ë‹µ ìƒì„¸ ë¶„ì„
print('\nğŸ” 4096 í† í° ì‘ë‹µ ë¶„ì„:')
max_token_responses = df[df['output_token_count'] == 4096]
print(f'  - 4096 í† í° ì‘ë‹µ ìˆ˜: {len(max_token_responses):,}')
print(f'  - ì „ì²´ ì‘ë‹µ ëŒ€ë¹„ ë¹„ìœ¨: {len(max_token_responses) / len(df) * 100:.2f}%')

if len(max_token_responses) > 0:
    print(f'  - 4096 í† í° ì‘ë‹µì´ ìˆëŠ” ë¬¸ì œ ìˆ˜: {max_token_responses["problem_id"].nunique()}')
    print(f'  - ì „ì²´ ë¬¸ì œ ëŒ€ë¹„ ë¹„ìœ¨: {max_token_responses["problem_id"].nunique() / df["problem_id"].nunique() * 100:.2f}%')

# ë¬¸ì œë³„ í† í° ìˆ˜ í†µê³„
print('\nğŸ“‹ ë¬¸ì œë³„ í† í° ìˆ˜ í†µê³„:')
problem_stats = df.groupby('problem_id')['output_token_count'].agg([
    'count', 'mean', 'min', 'max', 'std'
]).round(2)

print(f'  - ë¬¸ì œë‹¹ í‰ê·  ì‘ë‹µ ìˆ˜: {problem_stats["count"].mean():.1f}')
print(f'  - ë¬¸ì œë‹¹ í‰ê·  í† í° ìˆ˜: {problem_stats["mean"].mean():.1f}')
print(f'  - ë¬¸ì œë‹¹ ìµœëŒ€ í† í° ìˆ˜ í‰ê· : {problem_stats["max"].mean():.1f}')
print(f'  - ë¬¸ì œë‹¹ í† í° ìˆ˜ í‘œì¤€í¸ì°¨ í‰ê· : {problem_stats["std"].mean():.1f}')

# í† í° ìˆ˜ê°€ ë§ì€ ìƒìœ„ ë¬¸ì œë“¤
print('\nğŸ† í† í° ìˆ˜ê°€ ë§ì€ ìƒìœ„ 5ê°œ ë¬¸ì œ:')
top_problems = problem_stats.nlargest(5, 'max')
for i, (problem_id, stats) in enumerate(top_problems.iterrows(), 1):
    print(f'  {i}. ë¬¸ì œ ID: {problem_id}')
    print(f'     - ì‘ë‹µ ìˆ˜: {stats["count"]}')
    print(f'     - í‰ê·  í† í° ìˆ˜: {stats["mean"]:.1f}')
    print(f'     - ìµœëŒ€ í† í° ìˆ˜: {stats["max"]}')
    print(f'     - í‘œì¤€í¸ì°¨: {stats["std"]:.1f}')

print('\nâœ… output_token_count í†µê³„ ë¶„ì„ ì™„ë£Œ!')
