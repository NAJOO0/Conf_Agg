"""
Stage 3: ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
"""
import os
import sys
from pathlib import Path
import hydra
from omegaconf import DictConfig
import logging
import torch

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from src.models.grpo_trainer import GRPOTrainer
from src.data.training_dataset import create_training_dataloader, create_validation_dataloader
from src.utils.logging import setup_logging

logger = logging.getLogger(__name__)


@hydra.main(version_base=None, config_path="../config", config_name="config")
def main(cfg: DictConfig) -> None:
    """Stage 3 ë©”ì¸ í•¨ìˆ˜"""
    
    # ë¡œê¹… ì„¤ì •
    log_file = os.path.join(cfg.paths.log_dir, "stage3_train.log")
    setup_logging(
        log_level=cfg.experiment.get("log_level", "INFO"),
        log_file=log_file,
        wandb_enabled=cfg.experiment.wandb.enabled,
        wandb_project=cfg.experiment.wandb.project,
        wandb_tags=cfg.experiment.wandb.tags
    )
    
    logger.info("ğŸš€ Stage 3: ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    logger.info(f"ì„¤ì •: {cfg.training}")
    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(cfg.paths.model_dir, exist_ok=True)
    
    # ì…ë ¥ íŒŒì¼ ê²½ë¡œ í™•ì¸
    train_data_path = os.path.join(cfg.paths.data_dir, "curated", "train_curated.parquet")
    validation_data_path = os.path.join(cfg.paths.data_dir, "curated", "validation_curated.parquet")
    
    if not os.path.exists(train_data_path):
        logger.error(f"í›ˆë ¨ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {train_data_path}")
        logger.error("ë¨¼ì € Stage 2ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”: python scripts/stage2_curate.py")
        return
    
    # ë°ì´í„°ë¡œë” ìƒì„±
    logger.info("ë°ì´í„°ë¡œë” ìƒì„± ì¤‘...")
    train_dataloader = create_training_dataloader(
        train_data_path,
        batch_size=cfg.training.training.batch_size,
        shuffle=True,
        num_workers=4
    )
    
    validation_dataloader = None
    if os.path.exists(validation_data_path):
        validation_dataloader = create_validation_dataloader(
            validation_data_path,
            batch_size=cfg.training.training.batch_size,
            shuffle=False,
            num_workers=4
        )
        logger.info(f"ê²€ì¦ ë°ì´í„°ë¡œë” ìƒì„±: {len(validation_dataloader)} ë°°ì¹˜")
    
    logger.info(f"í›ˆë ¨ ë°ì´í„°ë¡œë” ìƒì„±: {len(train_dataloader)} ë°°ì¹˜")
    
    # GRPO íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
    logger.info("GRPO íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™” ì¤‘...")
    trainer = GRPOTrainer(
        model_name=cfg.model.base_model,
        lora_config=cfg.training.lora if cfg.training.method == "lora" else None,
        grpo_config=cfg.training.grpo,
        training_config=cfg.training.training,
        device=cfg.experiment.device
    )
    
    # í›ˆë ¨ ì‹¤í–‰
    logger.info("ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    trainer.train(
        train_dataset=train_dataloader,
        validation_dataset=validation_dataloader,
        save_dir=cfg.paths.model_dir
    )
    
    logger.info("âœ… Stage 3 ì™„ë£Œ")
    logger.info(f"í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {cfg.paths.model_dir}")


if __name__ == "__main__":
    main()

